{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-fmvDZhCM78x",
        "_T7BKfA-gauG"
      ],
      "authorship_tag": "ABX9TyMTDrmMahvPW/9LvjUz0Fr0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pc-Jiang/math_in_deep_learning/blob/main/DSC_291_SP23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DSC 291 Mathmatics in Deep Learning, SP23\n",
        "Advisor: Mikhail Belkin\n",
        "\n",
        "Author: Pengcen Jiang, Bin Wang"
      ],
      "metadata": {
        "id": "Wu1mT0KsGSct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import packages and set random seed.\n",
        "\n"
      ],
      "metadata": {
        "id": "AdhigL5wk12E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "NBeePU9YZl3r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import OrderedDict\n",
        "from copy import deepcopy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import sklearn.metrics\n",
        "import seaborn as sns\n",
        "import random\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "MAP_LOC = \"cuda:0\" if USE_CUDA else torch.device('cpu')\n",
        "\n",
        "def set_seed(seed = 1234):\n",
        "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
        "    This is for REPRODUCIBILITY.'''\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    \n",
        "set_seed()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define basic blocks and functions. "
      ],
      "metadata": {
        "id": "jeXs-RtvkyjH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define configurations class. "
      ],
      "metadata": {
        "id": "xSFTT7hIKMfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LearnFixedPointConfig(object):\n",
        "    def __init__(self):\n",
        "        # params for model\n",
        "        self.hidden_size = 100\n",
        "        self.nonlinearity = None\n",
        "        self.dim_in = 10\n",
        "        self.batch_size = 1\n",
        "        self.initialization = None\n",
        "        self.use_bias = True\n",
        "        self.time_steps = 10\n",
        "        self.ct = False\n",
        "        self.tau = 0\n",
        "\n",
        "        # params for training\n",
        "        self.lr = 0.001\n",
        "        self.optimizer_type = 'SGD'\n",
        "        self.momentum = 0\n",
        "        self.wdecay = 0\n",
        "        self.num_ep = 1000\n",
        "        self.add_noise = False\n",
        "\n",
        "        # params for generating data\n",
        "        self.std_fp = 1\n",
        "        self.mean_fp = 0\n",
        "        \n",
        "\n",
        "    def update(self, new_config):\n",
        "        self.__dict__.update(new_config.__dict__)\n",
        "\n",
        "    def __str__(self):\n",
        "        return str(self.__dict__)"
      ],
      "metadata": {
        "id": "IRsB6j4zJD1Y"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define RNN class. "
      ],
      "metadata": {
        "id": "PZqxpMGfKSVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IdentityAct(object):\n",
        "    def __call__(self, tensor):\n",
        "        return tensor\n",
        "\n",
        "\n",
        "class VanillaRNNCell(nn.Module):\n",
        "    # (N, L, H_{in}): N, batch size, L, squence length, H_{in}, input size\n",
        "    def __init__(self, config):\n",
        "        super(VanillaRNNCell, self).__init__()\n",
        "        self.input_size = config.dim_in\n",
        "        self.output_size = config.dim_in\n",
        "        self.hidden_size = config.hidden_size\n",
        "        self.nonlinearity = config.nonlinearity\n",
        "        self.use_bias = config.use_bias\n",
        "        self.initialization = config.initialization\n",
        "        self.ct = config.ct\n",
        "        self.tau = config.tau\n",
        "\n",
        "        self.weight_ih = nn.Parameter(\n",
        "            torch.zeros((self.hidden_size, self.input_size)))\n",
        "        self.weight_hh = nn.Parameter(\n",
        "            torch.zeros((self.hidden_size, self.hidden_size)))\n",
        "        self.weight_ho = nn.Parameter(\n",
        "            torch.zeros((self.output_size, self.hidden_size)))\n",
        "        self.bias = nn.Parameter(torch.zeros(self.hidden_size, 1))\n",
        "        self.bias_out = nn.Parameter(torch.zeros(self.output_size, 1))\n",
        "        self.reset_parameters()\n",
        "\n",
        "        if self.nonlinearity is None:\n",
        "            self.act = IdentityAct()\n",
        "        elif self.nonlinearity == \"tanh\":\n",
        "            self.act = torch.tanh\n",
        "        elif self.nonlinearity == \"relu\":\n",
        "            self.act = F.relu\n",
        "        else:\n",
        "            raise RuntimeError(\"Unknown nonlinearity: {}\".format(\n",
        "                self.nonlinearity))\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # add: bias-false\n",
        "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
        "        \n",
        "        if self.initialization is None:\n",
        "            for name, weight in self.named_parameters():\n",
        "              if 'bias' in name:\n",
        "                  if not self.use_bias:\n",
        "                      weight.requires_grad = False\n",
        "        elif self.initialization == 'uniform':\n",
        "            for name, weight in self.named_parameters():\n",
        "                if 'bias' in name:\n",
        "                    if not self.use_bias:\n",
        "                        weight.requires_grad = False\n",
        "                    else:\n",
        "                        nn.init.uniform_(weight, -stdv, stdv)\n",
        "                else:\n",
        "                    nn.init.uniform_(weight, -stdv, stdv)\n",
        "        else:\n",
        "            raise RuntimeError(\"Unknown initialization: {}\".format(self.initialization)) \n",
        "\n",
        "    def forward(self, inp, hidden_in):\n",
        "        inp = torch.unsqueeze(inp, 2)\n",
        "        hidden_in = torch.unsqueeze(hidden_in, 2)\n",
        "        if not self.ct:\n",
        "            hidden_out = self.act(\n",
        "                torch.matmul(self.weight_ih, inp) +\n",
        "                torch.matmul( self.weight_hh, hidden_in) + self.bias)\n",
        "        else:\n",
        "            alpha = 1 / self.tau\n",
        "            hidden_out = (1 - alpha) * hidden_in \\\n",
        "                         + alpha * self.act(torch.matmul(self.weight_ih, inp)\n",
        "                                            + torch.matmul(self.weight_hh, hidden_in)\n",
        "                                            + self.bias\n",
        "                                            )\n",
        "\n",
        "        output = torch.matmul(self.weight_ho, hidden_out) + self.bias_out\n",
        "        hidden_out = torch.squeeze(hidden_out, 2)\n",
        "        output = torch.squeeze(output, 2)\n",
        "\n",
        "        return [hidden_out, output]\n",
        "\n",
        "    def init_hidden(self, batch_s):\n",
        "        return torch.zeros(batch_s, self.hidden_size).to(DEVICE)"
      ],
      "metadata": {
        "id": "glHb1YSTZrRc"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the function to get the fixed point. "
      ],
      "metadata": {
        "id": "-fmvDZhCM78x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fixed_point(config):\n",
        "    dim = config.dim_in\n",
        "    fixed_point = torch.randn(1, dim).to(DEVICE) * config.std_fp + config.mean_fp\n",
        "    return fixed_point\n",
        "\n",
        "def add_noise(fixed_point, mean=0, std=0.1):\n",
        "    return fixed_point + torch.randn(fixed_point.size()).to(DEVICE) * std + mean"
      ],
      "metadata": {
        "id": "CXOgBFymM7P7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the training function"
      ],
      "metadata": {
        "id": "SgJwmbH4HFvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fixed_point(config, model, fixed_point):\n",
        "    # initialize optimizer\n",
        "    if config.optimizer_type == 'Adam':\n",
        "        optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad,\n",
        "                        model.parameters()),\n",
        "                        lr=config.lr,\n",
        "                        weight_decay=config.wdecay)\n",
        "    elif config.optimizer_type == 'SGD':\n",
        "        optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad,\n",
        "                       model.parameters()),\n",
        "                       lr=config.lr,\n",
        "                       momentum=config.momentum,\n",
        "                       weight_decay=config.wdecay)\n",
        "    else:\n",
        "        raise NotImplementedError('optimizer not implemented')\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    task_loss_list = []\n",
        "    ep_list = []\n",
        "\n",
        "    count = 1\n",
        "    for ep in range(config.num_ep):\n",
        "        hidden = model.init_hidden(config.batch_size)\n",
        "        model.train()\n",
        "        loss = 0.0 \n",
        "        optimizer.zero_grad()\n",
        "        for step in range(config.time_steps):\n",
        "            \n",
        "            if config.add_noise:\n",
        "                fixed_point = add_noise(fixed_point)\n",
        "            [hidden, output] = model(fixed_point, hidden)\n",
        "            task_loss = criterion(output, fixed_point)\n",
        "            loss += task_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        task_loss_list.append((loss/config.time_steps).item())\n",
        "        ep_list.append(count)\n",
        "        if count % 100 == 0: \n",
        "            print('TRAIN | Epoch: {}/{} | Loss: {:.2f}'.format(ep+1, config.num_ep, loss/config.time_steps))\n",
        "        count += 1\n",
        "\n",
        "    return model, optimizer, task_loss_list, ep_list\n"
      ],
      "metadata": {
        "id": "p6IXhz5IG0cE"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the function to get different configs"
      ],
      "metadata": {
        "id": "_T7BKfA-gauG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vary_config(base_config, config_ranges, mode,\n",
        "                num_seed=1, default_name=False):\n",
        "    \"\"\"Return configurations.\n",
        "    adapted from https://github.com/gyyang/olfaction_evolution\n",
        "    Args:\n",
        "        base_config: BaseConfig object, a base configuration\n",
        "        config_ranges: a dictionary of hyperparameters values\n",
        "            config_ranges = {\n",
        "                'hp1': [hp1_val1, hp1_val2, ...],\n",
        "                'hp2': [hp2_val1, hp2_val2, ...],\n",
        "            }\n",
        "        mode: str, can take 'combinatorial' or 'sequential'\n",
        "        num_seed: int, number of random seeds\n",
        "        default_name: bool, whether to use auto_name function\n",
        "    Return:\n",
        "        config_df: a pandas data frame of configs,\n",
        "            each row is a config, each column is a variation of parameter\n",
        "    \"\"\"\n",
        "    assert 'seed' not in config_ranges.keys(), 'seed cannot be specified in config range'\n",
        "\n",
        "    keys = config_ranges.keys()\n",
        "    dims = [len(config_ranges[k]) for k in keys]\n",
        "\n",
        "    attribute_dict = {}\n",
        "    for key in keys:\n",
        "        attribute_dict[key] = []\n",
        "    attribute_dict['seed'] = []\n",
        "    attribute_dict['config'] = []\n",
        "\n",
        "    # Return combinatorial configurations,\n",
        "    # config_ranges should not have repetitive values\n",
        "    if mode == 'combinatorial':\n",
        "        n_max = int(np.prod(dims))\n",
        "        assert n_max > 0\n",
        "        for seed in range(num_seed):\n",
        "            for i in range(n_max):\n",
        "                new_config = deepcopy(base_config)\n",
        "                # Set up new config\n",
        "                new_config.seed = seed\n",
        "                indices = np.unravel_index(i, shape=dims)\n",
        "                for key, index in zip(keys, indices):\n",
        "                    val = config_ranges[key][index]\n",
        "                    setattr(new_config, key, val)\n",
        "                    attribute_dict[key].append(val)\n",
        "\n",
        "                attribute_dict['seed'].append(seed)\n",
        "                attribute_dict['config'].append(new_config)\n",
        "\n",
        "    # Return sequential configurations.\n",
        "    # config_ranges values should have equal length,\n",
        "    # otherwise this will only loop through the shortest one\n",
        "    elif mode == 'sequential':\n",
        "        n_max = np.min(dims)\n",
        "        assert n_max > 0\n",
        "        for seed in range(num_seed):\n",
        "            for i in range(n_max):\n",
        "                new_config = deepcopy(base_config)\n",
        "                # Set up new config\n",
        "                new_config.seed = seed\n",
        "                for key in keys:\n",
        "                    val = config_ranges[key][i]\n",
        "                    setattr(new_config, key, val)\n",
        "                    attribute_dict[key].append(val)\n",
        "\n",
        "                attribute_dict['seed'].append(seed)\n",
        "                attribute_dict['config'].append(new_config)\n",
        "    else:\n",
        "        raise ValueError('Unknown mode {}'.format(str(mode)))\n",
        "\n",
        "    configs_df = pd.DataFrame(attribute_dict)\n",
        "\n",
        "    for i, row in configs_df.iterrows():\n",
        "        config = row.loc['config']\n",
        "        if default_name:\n",
        "            config.model_name = str(i).zfill(6)\n",
        "        else:\n",
        "            name = 'model'\n",
        "            for key in keys:\n",
        "                name += '_' + str(key) + str(row.loc[key])\n",
        "\n",
        "            # replace char that are not suitable for path\n",
        "            name = name.replace(\",\", \"\").replace(\" \", \"_\")\n",
        "            name = name.replace(\"[\", \"_\").replace(\"]\", \"_\").replace(\".\", \"_\")\n",
        "            name = name.replace(\"'\", \"\")\n",
        "            config.model_name = name + '_s' + str(row.loc['seed'])\n",
        "\n",
        "    return configs_df\n",
        "\n",
        "def configs_df_unpack(configs_df):\n",
        "    \"\"\"\n",
        "    unpack configs_df to a list of configs\n",
        "    args:\n",
        "        configs_df: pandas.DataFrame, that contains all configs in an experiment\n",
        "    return:\n",
        "        config_list: unpacked list of configs\n",
        "    \"\"\"\n",
        "    config_list = list(configs_df.loc[:, 'config'])\n",
        "    return config_list"
      ],
      "metadata": {
        "id": "U1tOGnAEgaRz"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the network. "
      ],
      "metadata": {
        "id": "s7v1U5Akk8eP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def learn_fixed_point():\n",
        "    config = LearnFixedPointConfig()\n",
        "    config_ranges = OrderedDict()\n",
        "    config_ranges['dim_in'] = [10, 50, 100]\n",
        "    config_ranges['nonlinearity'] = [None, 'relu']\n",
        "    config_ranges['initialization'] = [None, 'uniform']\n",
        "    configs = vary_config(config,\n",
        "                config_ranges,\n",
        "                mode='combinatorial',\n",
        "                num_seed=1)\n",
        "    return configs"
      ],
      "metadata": {
        "id": "L5XMO7ecgjw0"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configs_df = learn_fixed_point()\n",
        "configs = configs_df_unpack(configs_df)\n",
        "for config in configs:\n",
        "    print(config)\n",
        "    model = VanillaRNNCell(config)\n",
        "    fixed_point = get_fixed_point(config)\n",
        "    print('Fixed point {} \\n'.format(fixed_point))\n",
        "    model, optimizer, task_loss_list, ep_list = train_fixed_point(config, model, fixed_point)\n",
        "    print('-------------------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfhBlYyjia53",
        "outputId": "655e088d-d4ee-4446-df6d-e07031596d28"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'hidden_size': 100, 'nonlinearity': None, 'dim_in': 10, 'batch_size': 1, 'initialization': None, 'use_bias': True, 'time_steps': 10, 'ct': False, 'tau': 0, 'lr': 0.001, 'optimizer_type': 'SGD', 'momentum': 0, 'wdecay': 0, 'num_ep': 1000, 'add_noise': False, 'std_fp': 1, 'mean_fp': 0, 'seed': 0, 'model_name': 'model_dim_in10_nonlinearityNone_initializationNone_s0'}\n",
            "Fixed point tensor([[ 0.1442, -0.8658,  0.0773, -1.7251,  0.5583,  1.3073,  0.2807,  0.4634,\n",
            "          1.8128, -0.8622]]) \n",
            "\n",
            "TRAIN | Epoch: 100/1000 | Loss: 0.68\n",
            "TRAIN | Epoch: 200/1000 | Loss: 0.46\n",
            "TRAIN | Epoch: 300/1000 | Loss: 0.30\n",
            "TRAIN | Epoch: 400/1000 | Loss: 0.20\n",
            "TRAIN | Epoch: 500/1000 | Loss: 0.14\n",
            "TRAIN | Epoch: 600/1000 | Loss: 0.09\n",
            "TRAIN | Epoch: 700/1000 | Loss: 0.06\n",
            "TRAIN | Epoch: 800/1000 | Loss: 0.04\n",
            "TRAIN | Epoch: 900/1000 | Loss: 0.03\n",
            "TRAIN | Epoch: 1000/1000 | Loss: 0.02\n",
            "-------------------------------------------------------------------\n",
            "{'hidden_size': 100, 'nonlinearity': None, 'dim_in': 10, 'batch_size': 1, 'initialization': 'uniform', 'use_bias': True, 'time_steps': 10, 'ct': False, 'tau': 0, 'lr': 0.001, 'optimizer_type': 'SGD', 'momentum': 0, 'wdecay': 0, 'num_ep': 1000, 'add_noise': False, 'std_fp': 1, 'mean_fp': 0, 'seed': 0, 'model_name': 'model_dim_in10_nonlinearityNone_initializationuniform_s0'}\n",
            "Fixed point tensor([[ 1.5203, -0.0591,  1.7457,  1.2466, -1.5596,  0.2954, -1.1358,  0.8855,\n",
            "          0.4313, -1.4765]]) \n",
            "\n",
            "TRAIN | Epoch: 100/1000 | Loss: 0.03\n",
            "TRAIN | Epoch: 200/1000 | Loss: 0.02\n",
            "TRAIN | Epoch: 300/1000 | Loss: 0.01\n",
            "TRAIN | Epoch: 400/1000 | Loss: 0.01\n",
            "TRAIN | Epoch: 500/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 600/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 700/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 800/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 900/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 1000/1000 | Loss: 0.00\n",
            "-------------------------------------------------------------------\n",
            "{'hidden_size': 100, 'nonlinearity': 'relu', 'dim_in': 10, 'batch_size': 1, 'initialization': None, 'use_bias': True, 'time_steps': 10, 'ct': False, 'tau': 0, 'lr': 0.001, 'optimizer_type': 'SGD', 'momentum': 0, 'wdecay': 0, 'num_ep': 1000, 'add_noise': False, 'std_fp': 1, 'mean_fp': 0, 'seed': 0, 'model_name': 'model_dim_in10_nonlinearityrelu_initializationNone_s0'}\n",
            "Fixed point tensor([[ 0.4626, -0.2935,  0.8873, -1.3751, -1.1717,  1.2574, -1.3392, -0.4483,\n",
            "          0.1524,  1.5845]]) \n",
            "\n",
            "TRAIN | Epoch: 100/1000 | Loss: 0.70\n",
            "TRAIN | Epoch: 200/1000 | Loss: 0.47\n",
            "TRAIN | Epoch: 300/1000 | Loss: 0.32\n",
            "TRAIN | Epoch: 400/1000 | Loss: 0.21\n",
            "TRAIN | Epoch: 500/1000 | Loss: 0.14\n",
            "TRAIN | Epoch: 600/1000 | Loss: 0.10\n",
            "TRAIN | Epoch: 700/1000 | Loss: 0.06\n",
            "TRAIN | Epoch: 800/1000 | Loss: 0.04\n",
            "TRAIN | Epoch: 900/1000 | Loss: 0.03\n",
            "TRAIN | Epoch: 1000/1000 | Loss: 0.02\n",
            "-------------------------------------------------------------------\n",
            "{'hidden_size': 100, 'nonlinearity': 'relu', 'dim_in': 10, 'batch_size': 1, 'initialization': 'uniform', 'use_bias': True, 'time_steps': 10, 'ct': False, 'tau': 0, 'lr': 0.001, 'optimizer_type': 'SGD', 'momentum': 0, 'wdecay': 0, 'num_ep': 1000, 'add_noise': False, 'std_fp': 1, 'mean_fp': 0, 'seed': 0, 'model_name': 'model_dim_in10_nonlinearityrelu_initializationuniform_s0'}\n",
            "Fixed point tensor([[ 2.0268, -2.1745,  0.3765, -0.4620,  0.3171, -1.1671, -0.8318,  0.8662,\n",
            "         -0.2336,  0.9146]]) \n",
            "\n",
            "TRAIN | Epoch: 100/1000 | Loss: 0.02\n",
            "TRAIN | Epoch: 200/1000 | Loss: 0.01\n",
            "TRAIN | Epoch: 300/1000 | Loss: 0.01\n",
            "TRAIN | Epoch: 400/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 500/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 600/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 700/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 800/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 900/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 1000/1000 | Loss: 0.00\n",
            "-------------------------------------------------------------------\n",
            "{'hidden_size': 100, 'nonlinearity': None, 'dim_in': 50, 'batch_size': 1, 'initialization': None, 'use_bias': True, 'time_steps': 10, 'ct': False, 'tau': 0, 'lr': 0.001, 'optimizer_type': 'SGD', 'momentum': 0, 'wdecay': 0, 'num_ep': 1000, 'add_noise': False, 'std_fp': 1, 'mean_fp': 0, 'seed': 0, 'model_name': 'model_dim_in50_nonlinearityNone_initializationNone_s0'}\n",
            "Fixed point tensor([[-1.3723, -0.7689,  0.4156, -0.6230,  0.4085,  0.0797, -0.7975,  0.6635,\n",
            "          0.4153, -1.4237,  0.3084, -1.8847, -1.7281,  0.0843, -0.0847,  1.3414,\n",
            "         -1.0716, -1.1812, -0.0060,  0.3120, -0.0953,  0.4232,  0.3465, -1.7883,\n",
            "          0.9988,  1.2475,  0.5878,  1.3607,  0.5393, -0.6990, -0.9115,  2.0685,\n",
            "          0.3162,  1.7336,  0.7765,  0.9941,  1.2695, -0.5870, -1.4616, -1.4120,\n",
            "          0.7566, -0.8800, -0.0148,  0.3201,  1.0722, -1.0236,  1.2081, -0.5784,\n",
            "         -1.6980,  1.6235]]) \n",
            "\n",
            "TRAIN | Epoch: 100/1000 | Loss: 0.99\n",
            "TRAIN | Epoch: 200/1000 | Loss: 0.91\n",
            "TRAIN | Epoch: 300/1000 | Loss: 0.84\n",
            "TRAIN | Epoch: 400/1000 | Loss: 0.78\n",
            "TRAIN | Epoch: 500/1000 | Loss: 0.72\n",
            "TRAIN | Epoch: 600/1000 | Loss: 0.66\n",
            "TRAIN | Epoch: 700/1000 | Loss: 0.61\n",
            "TRAIN | Epoch: 800/1000 | Loss: 0.56\n",
            "TRAIN | Epoch: 900/1000 | Loss: 0.52\n",
            "TRAIN | Epoch: 1000/1000 | Loss: 0.48\n",
            "-------------------------------------------------------------------\n",
            "{'hidden_size': 100, 'nonlinearity': None, 'dim_in': 50, 'batch_size': 1, 'initialization': 'uniform', 'use_bias': True, 'time_steps': 10, 'ct': False, 'tau': 0, 'lr': 0.001, 'optimizer_type': 'SGD', 'momentum': 0, 'wdecay': 0, 'num_ep': 1000, 'add_noise': False, 'std_fp': 1, 'mean_fp': 0, 'seed': 0, 'model_name': 'model_dim_in50_nonlinearityNone_initializationuniform_s0'}\n",
            "Fixed point tensor([[-1.1087,  0.3707, -0.7130, -0.4027,  0.3907,  0.5630,  0.8073,  0.4801,\n",
            "         -0.8430, -0.7597, -1.0947,  1.4412,  1.2007,  1.1485, -0.2262, -0.5400,\n",
            "          0.5720,  0.7924, -0.0266, -0.6868,  0.3811, -0.6229,  0.3945, -0.3468,\n",
            "         -1.2970, -2.5217, -0.5148,  1.5825, -1.2166,  1.4552, -0.9797,  0.7367,\n",
            "          0.3239, -0.8069, -0.7876, -2.0743,  0.6935, -0.6901, -0.9273, -1.2918,\n",
            "          1.2114,  0.4753,  0.3635, -1.1786,  1.0417,  0.3632,  0.7944, -0.4337,\n",
            "         -2.2522, -1.0513]]) \n",
            "\n",
            "TRAIN | Epoch: 100/1000 | Loss: 0.03\n",
            "TRAIN | Epoch: 200/1000 | Loss: 0.02\n",
            "TRAIN | Epoch: 300/1000 | Loss: 0.01\n",
            "TRAIN | Epoch: 400/1000 | Loss: 0.01\n",
            "TRAIN | Epoch: 500/1000 | Loss: 0.01\n",
            "TRAIN | Epoch: 600/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 700/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 800/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 900/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 1000/1000 | Loss: 0.00\n",
            "-------------------------------------------------------------------\n",
            "{'hidden_size': 100, 'nonlinearity': 'relu', 'dim_in': 50, 'batch_size': 1, 'initialization': None, 'use_bias': True, 'time_steps': 10, 'ct': False, 'tau': 0, 'lr': 0.001, 'optimizer_type': 'SGD', 'momentum': 0, 'wdecay': 0, 'num_ep': 1000, 'add_noise': False, 'std_fp': 1, 'mean_fp': 0, 'seed': 0, 'model_name': 'model_dim_in50_nonlinearityrelu_initializationNone_s0'}\n",
            "Fixed point tensor([[-1.2665e+00, -2.4982e-01, -8.3861e-01,  3.0251e-02, -7.9887e-01,\n",
            "         -1.9929e-01,  1.7994e+00, -7.1718e-01, -2.9485e-01, -5.3609e-01,\n",
            "          3.5742e-04,  4.8513e-01,  5.7334e-01,  3.6926e-01,  2.1809e+00,\n",
            "          1.7570e+00, -9.2842e-01,  7.2620e-01, -9.1026e-01,  6.2196e-02,\n",
            "         -6.0616e-01,  1.3214e+00, -1.2054e+00,  1.9934e+00, -1.6613e+00,\n",
            "          3.6380e-01,  1.1703e+00, -1.1084e+00, -4.0104e-01,  2.2035e-01,\n",
            "         -3.3119e-02, -4.0912e-01,  1.3917e+00, -7.9260e-02, -7.2435e-02,\n",
            "          4.7909e-01,  6.8018e-01,  9.0536e-01,  5.1790e-01, -1.2900e+00,\n",
            "         -5.1211e-01,  7.1304e-01, -1.8336e+00,  2.1574e-01, -1.4992e-01,\n",
            "          8.3743e-01, -1.7843e+00,  9.0531e-01,  5.2085e-01,  1.2047e+00]]) \n",
            "\n",
            "TRAIN | Epoch: 100/1000 | Loss: 0.88\n",
            "TRAIN | Epoch: 200/1000 | Loss: 0.81\n",
            "TRAIN | Epoch: 300/1000 | Loss: 0.75\n",
            "TRAIN | Epoch: 400/1000 | Loss: 0.69\n",
            "TRAIN | Epoch: 500/1000 | Loss: 0.64\n",
            "TRAIN | Epoch: 600/1000 | Loss: 0.59\n",
            "TRAIN | Epoch: 700/1000 | Loss: 0.54\n",
            "TRAIN | Epoch: 800/1000 | Loss: 0.50\n",
            "TRAIN | Epoch: 900/1000 | Loss: 0.46\n",
            "TRAIN | Epoch: 1000/1000 | Loss: 0.43\n",
            "-------------------------------------------------------------------\n",
            "{'hidden_size': 100, 'nonlinearity': 'relu', 'dim_in': 50, 'batch_size': 1, 'initialization': 'uniform', 'use_bias': True, 'time_steps': 10, 'ct': False, 'tau': 0, 'lr': 0.001, 'optimizer_type': 'SGD', 'momentum': 0, 'wdecay': 0, 'num_ep': 1000, 'add_noise': False, 'std_fp': 1, 'mean_fp': 0, 'seed': 0, 'model_name': 'model_dim_in50_nonlinearityrelu_initializationuniform_s0'}\n",
            "Fixed point tensor([[ 0.4513,  0.4484, -0.2202, -0.5934,  0.5559, -1.0558, -0.1076,  1.4298,\n",
            "         -1.2725,  1.4472,  0.7809, -1.5741,  0.3219, -1.2659,  1.9459, -0.3100,\n",
            "         -1.4233, -0.0894, -0.8939,  0.7144,  0.3809,  0.4589, -0.0788, -0.7893,\n",
            "          1.2643, -0.1521,  1.2077, -2.1452,  1.2516, -0.9697, -0.1179,  0.7213,\n",
            "          1.1241, -1.6997, -1.1069, -0.2569, -0.0816, -0.7144,  1.3024, -0.7565,\n",
            "         -0.3610,  0.7036,  0.0587,  1.7415,  0.5422,  1.6687, -0.5496,  0.8549,\n",
            "         -0.1814,  1.2279]]) \n",
            "\n",
            "TRAIN | Epoch: 100/1000 | Loss: 0.04\n",
            "TRAIN | Epoch: 200/1000 | Loss: 0.01\n",
            "TRAIN | Epoch: 300/1000 | Loss: 0.01\n",
            "TRAIN | Epoch: 400/1000 | Loss: 0.01\n",
            "TRAIN | Epoch: 500/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 600/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 700/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 800/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 900/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 1000/1000 | Loss: 0.00\n",
            "-------------------------------------------------------------------\n",
            "{'hidden_size': 100, 'nonlinearity': None, 'dim_in': 100, 'batch_size': 1, 'initialization': None, 'use_bias': True, 'time_steps': 10, 'ct': False, 'tau': 0, 'lr': 0.001, 'optimizer_type': 'SGD', 'momentum': 0, 'wdecay': 0, 'num_ep': 1000, 'add_noise': False, 'std_fp': 1, 'mean_fp': 0, 'seed': 0, 'model_name': 'model_dim_in100_nonlinearityNone_initializationNone_s0'}\n",
            "Fixed point tensor([[-0.8824, -0.5230, -0.1229, -0.1002,  0.0418,  0.0527, -0.1109, -0.4497,\n",
            "          1.2878,  0.1053,  0.0811, -0.6311,  1.5592, -0.0332,  1.1955,  1.3483,\n",
            "          1.0454,  0.1137, -1.5779, -0.3857, -0.8897,  0.1498, -0.2893,  2.4886,\n",
            "          0.6688,  0.4546,  1.9569,  2.4394,  1.3535,  0.8206,  1.7535,  1.1020,\n",
            "          0.9699,  0.5339,  0.5260,  0.7648,  1.5510, -1.1932,  0.6264,  0.4792,\n",
            "          0.7506, -0.4063,  1.8131, -1.1261,  0.9941, -0.1267, -0.7850, -0.5719,\n",
            "         -0.3028,  0.3415,  0.1106, -0.9590,  0.1170,  0.2867,  0.4050, -0.9107,\n",
            "          0.4517,  1.7122, -0.2187,  0.2046, -1.7719, -0.1455,  0.0425, -0.1467,\n",
            "         -0.0861, -1.0982, -0.3825,  0.9565,  0.4251,  1.3298, -1.4885, -0.4316,\n",
            "         -2.3984, -0.2313, -1.8484,  1.0780, -0.5188,  0.1704, -1.5055, -0.4235,\n",
            "         -0.6215,  0.4137, -1.0139, -2.5110, -1.3152, -0.5859,  0.7391, -0.7848,\n",
            "         -1.5717,  0.6644, -0.3509, -0.4603,  1.2476,  0.6339, -0.0297,  0.8960,\n",
            "         -1.2280, -2.2394,  0.7068, -1.3783]]) \n",
            "\n",
            "TRAIN | Epoch: 100/1000 | Loss: 1.01\n",
            "TRAIN | Epoch: 200/1000 | Loss: 0.97\n",
            "TRAIN | Epoch: 300/1000 | Loss: 0.93\n",
            "TRAIN | Epoch: 400/1000 | Loss: 0.90\n",
            "TRAIN | Epoch: 500/1000 | Loss: 0.86\n",
            "TRAIN | Epoch: 600/1000 | Loss: 0.83\n",
            "TRAIN | Epoch: 700/1000 | Loss: 0.80\n",
            "TRAIN | Epoch: 800/1000 | Loss: 0.77\n",
            "TRAIN | Epoch: 900/1000 | Loss: 0.74\n",
            "TRAIN | Epoch: 1000/1000 | Loss: 0.71\n",
            "-------------------------------------------------------------------\n",
            "{'hidden_size': 100, 'nonlinearity': None, 'dim_in': 100, 'batch_size': 1, 'initialization': 'uniform', 'use_bias': True, 'time_steps': 10, 'ct': False, 'tau': 0, 'lr': 0.001, 'optimizer_type': 'SGD', 'momentum': 0, 'wdecay': 0, 'num_ep': 1000, 'add_noise': False, 'std_fp': 1, 'mean_fp': 0, 'seed': 0, 'model_name': 'model_dim_in100_nonlinearityNone_initializationuniform_s0'}\n",
            "Fixed point tensor([[-1.3005, -1.3837, -0.1700, -0.3321, -0.2219, -0.8785, -0.3458, -2.4048,\n",
            "          0.1556,  1.6488,  1.4928,  1.3059, -1.3401, -0.4378, -2.2860,  1.2156,\n",
            "         -0.1068, -1.4552, -0.4275, -1.0773,  0.5466,  1.4573, -0.1463,  0.0917,\n",
            "          1.2674,  0.7110,  0.4275, -2.2427,  0.8913,  1.1457, -0.0435, -1.3871,\n",
            "         -0.3161,  1.2648, -0.9864,  0.4066, -0.1589, -1.2366,  2.0916,  0.1266,\n",
            "          0.0409,  0.1834, -0.6783,  1.1274, -0.4453,  0.5868,  1.5197, -1.8393,\n",
            "          0.1916,  1.2995, -0.5429,  0.2551,  0.4298,  0.1025, -1.5487, -0.8226,\n",
            "          1.1151,  1.0161, -1.0365,  0.5310,  0.1324, -0.0961, -0.1893, -0.0149,\n",
            "         -0.1929,  0.8281,  0.0389,  0.3949,  0.4945,  0.2972, -0.4484,  0.9638,\n",
            "         -0.2743, -0.9620, -0.5473,  0.0419,  0.7169,  1.2593,  0.2300,  0.6274,\n",
            "          1.2513,  0.7230,  0.2746, -1.2540, -1.6189,  0.2652, -0.3506, -2.8946,\n",
            "         -0.9049, -0.4082, -0.5978, -1.5795,  0.6896,  0.3925,  0.3619,  2.0790,\n",
            "          0.3726,  0.8819,  0.9810, -0.2790]]) \n",
            "\n",
            "TRAIN | Epoch: 100/1000 | Loss: 0.03\n",
            "TRAIN | Epoch: 200/1000 | Loss: 0.02\n",
            "TRAIN | Epoch: 300/1000 | Loss: 0.01\n",
            "TRAIN | Epoch: 400/1000 | Loss: 0.01\n",
            "TRAIN | Epoch: 500/1000 | Loss: 0.01\n",
            "TRAIN | Epoch: 600/1000 | Loss: 0.01\n",
            "TRAIN | Epoch: 700/1000 | Loss: 0.01\n",
            "TRAIN | Epoch: 800/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 900/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 1000/1000 | Loss: 0.00\n",
            "-------------------------------------------------------------------\n",
            "{'hidden_size': 100, 'nonlinearity': 'relu', 'dim_in': 100, 'batch_size': 1, 'initialization': None, 'use_bias': True, 'time_steps': 10, 'ct': False, 'tau': 0, 'lr': 0.001, 'optimizer_type': 'SGD', 'momentum': 0, 'wdecay': 0, 'num_ep': 1000, 'add_noise': False, 'std_fp': 1, 'mean_fp': 0, 'seed': 0, 'model_name': 'model_dim_in100_nonlinearityrelu_initializationNone_s0'}\n",
            "Fixed point tensor([[ 6.5109e-02, -2.1050e+00, -9.3236e-02,  2.9205e+00, -1.4734e-02,\n",
            "         -1.5778e+00,  1.0833e+00,  9.6662e-01, -8.0442e-01,  2.9761e-01,\n",
            "         -4.5616e-01, -8.7839e-01,  4.5558e-01, -2.6944e-01,  1.5599e-03,\n",
            "          2.2203e-01,  1.6115e+00,  5.4845e-01, -1.3924e+00, -3.8494e-01,\n",
            "         -4.9961e-01,  2.9007e-01, -9.1897e-01, -5.1811e-01,  5.9884e-02,\n",
            "         -8.3011e-01,  1.4467e+00,  2.7830e-02, -1.3417e-03, -3.4624e-01,\n",
            "          1.2664e-01, -1.0105e+00,  2.6789e-02, -1.9792e+00, -1.8621e+00,\n",
            "         -3.8610e-01,  1.0182e+00,  9.7545e-01,  5.2222e-01, -8.2749e-01,\n",
            "         -2.1958e+00,  2.5173e+00,  2.1617e-02, -4.4003e-01,  5.2553e-01,\n",
            "         -2.3915e-01, -1.0582e+00, -6.4538e-01, -6.8748e-01, -8.5921e-01,\n",
            "         -9.4010e-01,  1.9146e+00,  1.5379e+00, -1.3865e+00, -4.9547e-01,\n",
            "         -6.6909e-03, -5.4045e-01,  1.1593e+00, -1.5484e+00, -3.0277e-01,\n",
            "         -3.1304e-01, -3.5033e-02, -1.2041e-01, -5.1930e-01,  6.0084e-01,\n",
            "         -1.7675e-01,  1.3440e-01, -1.9508e+00, -1.9409e-01, -4.5631e-01,\n",
            "          7.3429e-01, -5.3333e-01, -1.0654e+00, -7.9256e-02, -1.0739e+00,\n",
            "         -2.7880e-01, -1.3182e+00, -9.1713e-01,  2.4755e+00, -9.0059e-01,\n",
            "          2.1265e+00,  7.7703e-01,  2.0864e+00,  1.7014e+00,  9.0188e-01,\n",
            "          2.0821e-01,  1.8205e-01, -6.8806e-02,  6.2442e-01, -2.0853e+00,\n",
            "         -1.6627e+00, -1.6221e+00,  1.5820e+00,  2.4054e-01,  6.0262e-01,\n",
            "         -9.4974e-01,  9.7916e-01,  1.1112e+00,  1.2236e+00,  6.7653e-01]]) \n",
            "\n",
            "TRAIN | Epoch: 100/1000 | Loss: 1.13\n",
            "TRAIN | Epoch: 200/1000 | Loss: 1.08\n",
            "TRAIN | Epoch: 300/1000 | Loss: 1.04\n",
            "TRAIN | Epoch: 400/1000 | Loss: 1.00\n",
            "TRAIN | Epoch: 500/1000 | Loss: 0.96\n",
            "TRAIN | Epoch: 600/1000 | Loss: 0.92\n",
            "TRAIN | Epoch: 700/1000 | Loss: 0.88\n",
            "TRAIN | Epoch: 800/1000 | Loss: 0.85\n",
            "TRAIN | Epoch: 900/1000 | Loss: 0.82\n",
            "TRAIN | Epoch: 1000/1000 | Loss: 0.78\n",
            "-------------------------------------------------------------------\n",
            "{'hidden_size': 100, 'nonlinearity': 'relu', 'dim_in': 100, 'batch_size': 1, 'initialization': 'uniform', 'use_bias': True, 'time_steps': 10, 'ct': False, 'tau': 0, 'lr': 0.001, 'optimizer_type': 'SGD', 'momentum': 0, 'wdecay': 0, 'num_ep': 1000, 'add_noise': False, 'std_fp': 1, 'mean_fp': 0, 'seed': 0, 'model_name': 'model_dim_in100_nonlinearityrelu_initializationuniform_s0'}\n",
            "Fixed point tensor([[-1.8527e+00,  1.5837e+00, -1.2049e+00,  1.9790e+00,  2.2444e+00,\n",
            "          1.5712e-01,  1.2598e+00, -9.2589e-01, -1.3535e+00, -1.6557e+00,\n",
            "          3.0542e+00,  5.5548e-01, -2.6166e-01,  6.1573e-01, -2.2373e-01,\n",
            "          7.7828e-01, -4.7327e-01, -1.6271e+00,  2.3062e+00, -3.0951e-02,\n",
            "          1.2408e+00, -1.8822e-01, -1.7737e+00, -8.8347e-01, -1.3889e-02,\n",
            "          1.8943e+00, -1.6690e+00,  4.0115e-01, -1.9069e-01,  5.1750e-01,\n",
            "         -7.5306e-02,  6.7384e-01, -4.9679e-01, -8.1169e-04, -5.6197e-01,\n",
            "          4.3177e-01, -7.5499e-01, -5.8974e-02, -1.9787e+00,  8.1930e-02,\n",
            "          3.3308e-01,  9.5265e-01,  8.8990e-01,  6.2170e-01, -8.0111e-01,\n",
            "          8.7456e-01,  1.8361e+00,  1.4666e+00, -4.6131e-02, -1.0862e+00,\n",
            "         -1.7331e-01,  7.5000e-01, -1.6915e-01, -1.9239e+00, -1.8748e-01,\n",
            "         -1.5863e+00,  1.2222e-01, -1.0758e-01, -1.5248e+00,  1.6927e+00,\n",
            "         -1.5251e+00, -8.0905e-01,  7.9387e-02, -6.4226e-01,  1.6435e+00,\n",
            "          1.3132e+00, -1.6623e-01,  3.4771e-01, -1.1415e+00, -8.7275e-01,\n",
            "          5.3062e-01, -5.9170e-01,  4.0621e-02, -2.4587e-01,  6.4161e-01,\n",
            "          1.7215e-01,  2.5680e-01,  1.0698e+00,  7.0394e-02,  3.7996e-01,\n",
            "          4.6559e-01,  1.2553e+00, -1.2541e+00, -1.8732e+00, -3.3783e-01,\n",
            "          9.1774e-02, -2.3493e+00, -5.7334e-01, -5.9843e-01, -9.1281e-01,\n",
            "          7.3013e-02,  1.5628e+00, -6.0633e-02,  1.7042e+00, -9.3556e-01,\n",
            "          1.6274e+00,  6.2586e-01,  9.9237e-01,  2.3470e+00, -1.2103e+00]]) \n",
            "\n",
            "TRAIN | Epoch: 100/1000 | Loss: 0.04\n",
            "TRAIN | Epoch: 200/1000 | Loss: 0.02\n",
            "TRAIN | Epoch: 300/1000 | Loss: 0.01\n",
            "TRAIN | Epoch: 400/1000 | Loss: 0.01\n",
            "TRAIN | Epoch: 500/1000 | Loss: 0.01\n",
            "TRAIN | Epoch: 600/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 700/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 800/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 900/1000 | Loss: 0.00\n",
            "TRAIN | Epoch: 1000/1000 | Loss: 0.00\n",
            "-------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}